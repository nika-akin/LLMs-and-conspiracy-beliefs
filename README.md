
# LLMs and conspiracy beliefs

This repository is a collaborative effort to leverage large language models and theory-derived research.

The use of large language models, such as OpenAI’s GPT-3, which are trained on vast amounts of text data, has brought about a significant paradigm shift in the scientific community, as they can produce consistent response distributions, such as moral values or decision-making heuristics (see Horton, 2023). The research project’s two main objectives relate to: leveraging large language models for annotation of features and prompt sensitivity.


## Documentation

[Documentation](https://linktodocumentation)


## Installation

R-Dependencies

```bash
  library(tidyverse)
```
    
Python-Dependencies

```bash
  import pandas as pd
```
    
## Acknowledgements

 - [Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., & Neubig, G. (2023). Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. ACM Computing Surveys, 55(9), 1-35.](https://arxiv.org/pdf/2107.13586.pdf)


## Feedback

If you have any feedback, please reach out at veronika.batzdorfer@gesis.org


## Data
- Conspiracy theory data
## Contributing

Contributions are always welcome!

See `contributing.md` for ways to get started.

Please adhere to this project's `code of conduct`.
