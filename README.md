
# Conspiracy beliefs and Pre-trained Generative Language Models

This repository is a collaborative effort, as part of the [BIGSSS 2023 summmer school](https://bigssscss.janlo.de/democratic-debate-2023-bremen/projects/). This project deals with: *"Simulating Conspiracy Beliefs with Large Language Models"*.

The use of large language models, such as OpenAIâ€™s GPT-3, which are trained on vast amounts of text data, has brought about a significant paradigm shift in the scientific community, as they can produce consistent response distributions, such as moral values or decision-making heuristics (see Horton, 2023). The research projectâ€™s two main objectives relate to: leveraging large language models for annotation of conspiracy features and prompt sensitivity.


## Project Phase

| Date      | Duration |Milestone|
| --------------- | ---- | ----------- |
| 04-07 | ðŸ•¥14:00-15:30 | xx
| 05-07   |  ðŸ•¥14:00-15:30 | xx
| 06-07     |  ðŸ•¥14:00-15:30 | xx
| 07-07   |  ðŸ•¥13:00-14:30 | xx 
| 10-07 |  ðŸ•¥09:30-12:00, 13:30-15:00, 16:30-17:30 | xx
| 11-07 |  ðŸ•¥09:30-12:00, 13:30-15:00, 16:30-17:30 | xx
| 12-07   | ðŸ•¥09:00-12:00 | final presentation

## Resources -- Prompting LLMs

 - GÃ¶tz, F. M., Maertens, R., Loomba, S., & van der Linden, S. (2023). Let the algorithm speak: How to use neural networks for automatic item generation in psychological scale development. *Psychological Methods*. Advance online publication. [osf](https://psyarxiv.com/m6s28/)
 - Horton, J. J. (2023). Large Language Models as Simulated Economic Agents: What Can We Learn from Homo Silicus?. arXiv preprint arXiv:2301.07543.
 - Jakesch, M., Hancock, J. T., & Naaman, M. (2023). Human heuristics for AI-generated language are flawed. Proceedings of the National Academy of Sciences, *120*(11), e2208839120. [https://doi.org/10.1073/pnas.2208839120](https://osf.io/284yv/)
 - Levy, S., Saxon, M., & Wang, W. Y. (2021). Investigating memorization of conspiracy theories in text generation. arXiv preprint [arXiv:2101.00379.](https://arxiv.org/abs/2101.00379)
 - Li, X., Li, Y., Liu, L., Bing, L., & Joty, S. (2022). Is GPT-3 a Psychopath? Evaluating Large Language Models from a Psychological Perspective. arXiv preprint [arXiv:2212.10529](https://arxiv.org/pdf/2212.10529.pdf).
 - Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., & Neubig, G. (2023). Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. *ACM Computing Surveys*, *55*(9), 1-35. [preprint arXiv:2302.03735](https://arxiv.org/pdf/2107.13586.pdf)
 - Madaan, A., Tandon, N., Gupta, P., Hallinan, S., Gao, L., Wiegreffe, S., ... & Clark, P. (2023). Self-refine: Iterative refinement with self-feedback. arXiv preprint [arXiv:2303.17651.](https://selfrefine.info/)
- Peng, B., Li, C., He, P., Galley, M., & Gao, J. (2023). Instruction Tuning with GPT-4 (arXiv:2304.03277). arXiv. [http://arxiv.org/abs/2304.03277](https://arxiv.org/abs/2304.03277)
 - Zhou, Y., Muresanu, A. I., Han, Z., Paster, K., Pitis, S., Chan, H., & Ba, J. (2023). Large Language Models Are Human-Level Prompt Engineers (arXiv:2211.01910). arXiv. [https://doi.org/10.48550/arXiv.2211.01910](https://arxiv.org/abs/2211.01910)


## Resources -- NLP
- Introduction to [Transformer-based Language Models](https://github.com/chkla/Transformers-MZES)
- General [computational social science resources](https://github.com/gesiscss/css_methods_python)
- [Media Research tool collection](https://docs.google.com/spreadsheets/d/1GHh7rw1XQqla9xvXg9hTNm67TGmeOXTu_Og_thIO8QI/edit#gid=1084385301)
- Tools by [SciencesPo Medialab](https://medialab.sciencespo.fr/en/tools/)

