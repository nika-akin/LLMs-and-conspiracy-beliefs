
# Conspiracy beliefs and Pre-trained Generative Language Models

This repository is a collaborative effort, as part of the [BIGSSS 2023 summmer school](https://bigssscss.janlo.de/democratic-debate-2023-bremen/projects/). This project deals with: *"Simulating Conspiracy Beliefs with Large Language Models"*.

The use of large language models, such as OpenAI’s GPT-3, which are trained on vast amounts of text data, has brought about a significant paradigm shift in the scientific community, as they can produce consistent response distributions, such as moral values or decision-making heuristics (see Horton, 2023). The research project’s two main objectives are differentiationg conspiracy from mainstream content by annotating conspiracy theories with GPT-3.5 based on five minimally sufficient features and understanding engagement (i.e., facebook reactions) with conspiratorial content.



## Data
<!--[Language of conspiracy (LOCO) corpus](https://pubmed.ncbi.nlm.nih.gov/34697754/)-->

<!--Miani, A., Hills, T., & Bangerter, A. (2021). LOCO: The 88-million-word language of conspiracy corpus. *Behavior research methods*, 1-24.-->

## Resources -- Prompting LLMs

<!-- - Götz, F. M., Maertens, R., Loomba, S., & van der Linden, S. (2023). Let the algorithm speak: How to use neural networks for automatic item generation in psychological scale development. *Psychological Methods*. Advance online publication. [osf](https://psyarxiv.com/m6s28/)
<!-- - Horton, J. J. (2023). Large Language Models as Simulated Economic Agents: What Can We Learn from Homo Silicus?. arXiv preprint arXiv:2301.07543.
<!-- - Jakesch, M., Hancock, J. T., & Naaman, M. (2023). Human heuristics for AI-generated language are flawed. Proceedings of the National Academy of Sciences, *120*(11), e2208839120. [https://doi.org/10.1073/pnas.2208839120](https://osf.io/284yv/)
<!-- - Levy, S., Saxon, M., & Wang, W. Y. (2021). Investigating memorization of conspiracy theories in text generation. arXiv preprint [arXiv:2101.00379.](https://arxiv.org/abs/2101.00379)
<!-- - Li, X., Li, Y., Liu, L., Bing, L., & Joty, S. (2022). Is GPT-3 a Psychopath? Evaluating Large Language Models from a Psychological Perspective. arXiv preprint [arXiv:2212.10529](https://arxiv.org/pdf/2212.10529.pdf).
<!-- - Liu, P., Yuan, W., Fu, J., Jiang, Z., Hayashi, H., & Neubig, G. (2023). Pre-train, prompt, and predict: A systematic survey of prompting methods in natural language processing. *ACM Computing Surveys*, *55*(9), 1-35. [preprint arXiv:2302.03735](https://arxiv.org/pdf/2107.13586.pdf)
<!-- - Madaan, A., Tandon, N., Gupta, P., Hallinan, S., Gao, L., Wiegreffe, S., ... & Clark, P. (2023). Self-refine: Iterative refinement with self-feedback. arXiv preprint [arXiv:2303.17651.](https://selfrefine.info/)
<!--- Peng, B., Li, C., He, P., Galley, M., & Gao, J. (2023). Instruction Tuning with GPT-4 (arXiv:2304.03277). arXiv. [http://arxiv.org/abs/2304.03277](https://arxiv.org/abs/2304.03277)
<!-- - Zhou, Y., Muresanu, A. I., Han, Z., Paster, K., Pitis, S., Chan, H., & Ba, J. (2023). Large Language Models Are Human-Level Prompt Engineers (arXiv:2211.01910). arXiv. [https://doi.org/10.48550/arXiv.2211.01910](https://arxiv.org/abs/2211.01910)


## Resources -- NLP
<!--- Introduction to [Transformer-based Language Models](https://github.com/chkla/Transformers-MZES)-->
<!--- General [computational social science resources](https://github.com/gesiscss/css_methods_python)-->
<!--- [Media Research tool collection](https://docs.google.com/spreadsheets/d/1GHh7rw1XQqla9xvXg9hTNm67TGmeOXTu_Og_thIO8QI/edit#gid=1084385301)-->
<!--- Tools by [SciencesPo Medialab](https://medialab.sciencespo.fr/en/tools/)-->

